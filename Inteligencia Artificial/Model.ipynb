{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8204 images belonging to 18 classes.\n",
      "Found 1751 images belonging to 18 classes.\n",
      "Found 1782 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_directories(base_dir, categories):\n",
    "    \"\"\"\n",
    "    Create directories for training, testing, and validation datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - base_dir (str): The base directory where the train, test, and validation directories will be created.\n",
    "    - categories (list): List of category names (sub-directory names) to create inside each of train, test, and validation directories.\n",
    "    \"\"\"\n",
    "    for subset in ['train', 'test', 'validation']:\n",
    "        for category in categories:\n",
    "            dir_path = os.path.join(base_dir, subset, category)\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            logging.info(f'Created directory: {dir_path}')\n",
    "\n",
    "def copy_images(source_dir, images, dest_dir):\n",
    "    \"\"\"\n",
    "    Copy images from source directory to destination directory.\n",
    "\n",
    "    Parameters:\n",
    "    - source_dir (str): The directory containing the source images.\n",
    "    - images (list): List of image filenames to copy.\n",
    "    - dest_dir (str): The destination directory where images will be copied.\n",
    "    \"\"\"\n",
    "    for image in images:\n",
    "        shutil.copy(os.path.join(source_dir, image), os.path.join(dest_dir, image))\n",
    "        logging.info(f'Copied {image} to {dest_dir}')\n",
    "\n",
    "def split_dataset(source_dir, base_dir, split_ratios=(0.7, 0.15, 0.15)):\n",
    "    \"\"\"\n",
    "    Split the dataset into training, testing, and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    - source_dir (str): The source directory containing subdirectories of images for each category.\n",
    "    - base_dir (str): The base directory where the split datasets will be stored.\n",
    "    - split_ratios (tuple): A tuple containing the ratios for splitting the dataset into train, test, and validation sets.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the split ratios do not sum to 1.\n",
    "    \"\"\"\n",
    "    if sum(split_ratios) != 1:\n",
    "        raise ValueError(\"Split ratios must sum to 1. Provided ratios sum to {:.2f}\".format(sum(split_ratios)))\n",
    "    \n",
    "    categories = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n",
    "    create_directories(base_dir, categories)\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(source_dir, category)\n",
    "        images = os.listdir(category_path)\n",
    "        np.random.shuffle(images)\n",
    "\n",
    "        train_split = int(len(images) * split_ratios[0])\n",
    "        test_split = int(len(images) * split_ratios[1])\n",
    "\n",
    "        train_images = images[:train_split]\n",
    "        test_images = images[train_split:train_split + test_split]\n",
    "        validation_images = images[train_split + test_split:]\n",
    "\n",
    "        copy_images(category_path, train_images, os.path.join(base_dir, 'train', category))\n",
    "        copy_images(category_path, test_images, os.path.join(base_dir, 'test', category))\n",
    "        copy_images(category_path, validation_images, os.path.join(base_dir, 'validation', category))\n",
    "        \n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    if img.mode == 'P' and 'transparency' in img.info:\n",
    "        img = img.convert('RGBA')\n",
    "        img = img.convert('RGB')\n",
    "    if img.mode == 'RGBA':\n",
    "        img = img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "def augment_train_dataset(train_path='Dataset_Split/train', augmented_path='augmented', width=150, height=150, batch_size=64):\n",
    "    os.makedirs(augmented_path, exist_ok=True)  # Create augmented_path directory if it does not exist\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(width, height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        save_to_dir=augmented_path,\n",
    "        save_prefix='aug',\n",
    "        save_format='png'\n",
    "    )\n",
    "\n",
    "    classes = train_generator.class_indices\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_generator):\n",
    "        if i >= len(train_generator):\n",
    "            break\n",
    "        for j in range(len(images)):\n",
    "            label_index = np.argmax(labels[j])\n",
    "            label = [k for k, v in classes.items() if v == label_index][0]\n",
    "            logging.info(f\"Augmented image {i * batch_size + j} for class {label}\")\n",
    "\n",
    "    # Printing a sample of the images generated in the preprocessing\n",
    "    num_imgs = min(images.shape[0], 20)\n",
    "    fig, axarr = plt.subplots(2, 10, figsize=(5, 5))\n",
    "    for i in range(num_imgs):\n",
    "        row = i // 10\n",
    "        col = i % 10\n",
    "        axarr[row, col].imshow(images[i])\n",
    "        axarr[row, col].set_title(label)\n",
    "        axarr[row, col].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def load_datasets(base_dir='Dataset_Split', target_size=(150, 150), batch_size=32):\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'train'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'test'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        os.path.join(base_dir, 'validation'),\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_generator, test_generator, validation_generator\n",
    "\n",
    "def setup_and_split_dataset(source_dir='Data', base_dir='Dataset_Split', split_ratios=(0.7, 0.15, 0.15)):\n",
    "    \"\"\"\n",
    "    Set up logging, define directories, and split the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - source_dir (str): The source directory containing subdirectories of images for each category.\n",
    "    - base_dir (str): The base directory where the split datasets will be stored.\n",
    "    - split_ratios (tuple): A tuple containing the ratios for splitting the dataset into train, test, and validation sets.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    try:\n",
    "        split_dataset(source_dir, base_dir, split_ratios)\n",
    "    except ValueError as e:\n",
    "        logging.error(e)\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #setup_and_split_dataset()\n",
    "    #augment_train_dataset()\n",
    "    train_generator, test_generator, validation_generator = load_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
